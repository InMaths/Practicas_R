{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9415cf60-2a7f-4695-82b0-22f7aaec7a15",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 30px;\">\n",
    "Statistics Labs<br/>\n",
    "</div>\n",
    "<div style=\"text-align: center; font-size: 30px;\">\n",
    "Probability papers\n",
    "</div>\n",
    "<div style=\"text-align: center; font-size: 16px; font-style: italic\">\n",
    "Material prepared by M. Dolores Frías, Jesús Fernández, and Carmen M. Sordo, senior lectures from the Department of Applied Mathematics and Computer Science at the University of Cantabria.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77abfbd-c549-4202-82df-802ce74d5f59",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "Graphical methods have traditionally been used in engineering due to their simplicity and useful\n",
    "for analyzing data and understanding its structure. With the popularization of computers as a usual\n",
    "work tool, the graphic representation has gone from being done manually to be done on the computer.\n",
    "One of the traditional graphical methods that can be easily implemented in R is the one based on the\n",
    "probability paper concept.\n",
    "\n",
    "The basic idea of probability paper of a two-parameter family of distributions is to modify the\n",
    "scales of the axes for the random variable and for the accumulated probability, in such a way that this\n",
    "family becomes a family of straight lines. In this way, when the CDF is plotted in that paper, the aspect\n",
    "of the graph (straight line or not) is used to decide if the data come from that family of distributions\n",
    "or not. In addition, the parameters of the particular distribution that best fits can be obtained from\n",
    "the representation.\n",
    "\n",
    "# Empirical cumulative distribution function (ECDF)\n",
    "\n",
    "If we take a sample from a population whose distribution function we do not know, we can construct a *sample distribution function* known as the **empirical distribution function** (ECDF). This function will give us the probability of obtaining a value less than or equal to one given from the\n",
    "obtained sample. To build it, we order the values $x_i$ that the variable has\n",
    "taken in our sample of size $n$. The element that occupies the i-th place once\n",
    "sorted the sample is known as a **statistic of order** $i$, and we will\n",
    "denote it by $x_{i:n}$. \n",
    "\n",
    "The ECDF assigns to each value obtained in the sample a cumulative probability $i/n$:\n",
    "\n",
    "$S_n(x_{i:n})= \\frac{i}{n}$\n",
    "\n",
    "Actually, this function is defined on the entire real line and shows jumps. In R, it can be obtained using the function `ecdf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436e3caa-cabc-4eb6-97dd-8f8280d72058",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.i <- rnorm(50)       # Sample os size 50 from N(0,1)\n",
    "Sn <- ecdf(x.i)        # ECDF\n",
    "Sn(1.2)                # We can use it as a function...\n",
    "plot(Sn)               # ... plot consider it in a particular way\n",
    "curve(pnorm(x), col=\"red\", add=T)  # We can compare it with the distribution from the original population\n",
    "legend(\"topleft\", legend=c(\"ecdf(rnorm(50))\", expression(\"F\"[N(0,1)]*\"(x)\")),\n",
    "       col=c(\"black\",\"red\"), lty=1, box.lty=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef739da9-3d5c-4fc7-8379-6f6d7c9e794f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This empirical cumulative distribution function is the one we want to represent\n",
    "on the probability paper that is, in a graph with new scales on the axes, in\n",
    "such a way that its points are forming a straight line instead of the curve ploted above. \n",
    "\n",
    "However, in the case of many families of\n",
    "distributions, the value $1$ (which reaches $S_n(x_{n:n})$), when the scale\n",
    "transformation is applied become $\\infty $. Therefore, it is impossible to draw\n",
    "it. One solution to this problem is to use other plotting positions different\n",
    "from $i/n$ to assign the cumulative probability up to each sample data. The\n",
    "following table summarizes different formulas to obtain plotting positions\n",
    "proposed by different authors:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057a020b-4432-4e4e-bc8e-313e497968d4",
   "metadata": {},
   "source": [
    "<div><img alt=\"Plotting positions\" src=\"./figuras/tabla_punteo_en.png\" width=\"250\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fe9cc2-6648-4d47-bf46-bf9bdc60620f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In what follows we will use Hazen's formula, although in R we can use any other\n",
    "without much difficulty. For the development of this practice we have\n",
    "programmed a series of functions contained in the file *papeles.R* which,\n",
    "among others, also includes functions to calculate these scores as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf7a2c1-8d38-4e85-a5cf-5225a643b385",
   "metadata": {},
   "outputs": [],
   "source": [
    "source(\"functions/papeles.R\")    # Load the file with the functions for this practice\n",
    "punteo.hazen(50)       # Return the probabilities assigned by Hazen's formula to a sample of size 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b93834-8161-4ccf-8e97-e23ddde77b45",
   "metadata": {},
   "source": [
    "Remember that for using all the functions programmed in *papeles.R* in your RStudio session, you should run the `source(\"papeles.R\")` command only once at the beginning of the script. Then all the functions we need will be loaded. Also, for this command to work, we must have established the working directory that contains the file *papeles.R* with the command `setwd()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68469f4-5dc3-47d7-a57a-62ac8b93bd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "punteo.gringorten(50) # With Gringorten formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56dac86-73cf-4784-96eb-c6288c1662d9",
   "metadata": {},
   "source": [
    "R also has a generic function `ppoints(n,a)` that implements the formula $p_{i:n}=\\frac{i-a}{n+(1-2a)}$ that allows calculating these and other plotting positions depending on the value of a. For example, the two cases above can be obtained as `ppoints(50,0.5)` (Hazen) and `ppoints(50,0.44)` (Gringorten)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e64808-c3fb-46f4-97c2-462df3c0c5a7",
   "metadata": {},
   "source": [
    "# Basics of the probability paper\n",
    "\n",
    "The probability paper is simply a paper in which the scales have been\n",
    "modified in such a way that the distribution functions of a certain family,\n",
    "when drawn in it become a family of straight lines.\n",
    "\n",
    "Given $F_X(x;\\theta_1,\\theta_2)$ a two-parameter family of distributions, where $\\theta_1$ and $\\theta_2$ are the parameters, we look for a transformation \\begin{equation}\n",
    "\\xi =g(x)\\quad;\\quad \\eta =h(y)\\quad \\quad \\quad (1)\n",
    "\\end{equation}\n",
    "such that the family of curves\n",
    "\\begin{equation}\n",
    "y=F_X(x;\\theta_1,\\theta_2)\\quad \\quad \\quad (2)\n",
    "\\end{equation}\n",
    "when they transform by (1) become in a family of straight lines:\n",
    "\\begin{equation}\n",
    "h(y)=h[F_X(x;\\theta_1,\\theta_2)]=ag(x)+b\\quad \\quad \\Leftrightarrow \\quad \\quad \\eta\n",
    "=a\\xi +b  \\quad \\quad \\quad (3)\n",
    "\\end{equation}\n",
    "where the variable $\\eta $ is called the reduced variable and $a=a(\\theta_1,\\theta_2)$ and $b=b(\\theta_1,\\theta_2)$ are, respectively, the slope and the intercept of the line to which $F_X(x;\\theta_1,\\theta_2)$ becomes.\n",
    "\n",
    "Therefore, for there to be a probability paper associated with a certain\n",
    "family of distribution functions $F_X(x;\\theta_1,\\theta_2)$ requires that\n",
    "\\begin{equation}\n",
    "F_X(x;\\theta_1,\\theta_2)=h^{-1}[ag(x)+b]\\quad \\quad \\quad (4)\n",
    "\\end{equation}\n",
    "\n",
    "Given a known family of distributions, we will have to find the form of the $h$\n",
    "and $g$ transformations that make the probability paper possible for that\n",
    "family. In this practice we will refresh one of the transformations seen in\n",
    "class that makes normal paper possible and we will analyze in detail the\n",
    "necessary transformation of exponential paper. In addition to these two roles,\n",
    "we will also use the rest of the probability papers whose transformations we\n",
    "have seen in class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93120fe-f0ac-4d6f-ac69-4fc0eae78dec",
   "metadata": {},
   "source": [
    "# Normal probability paper plot\n",
    "\n",
    "If $F_X(x;\\mu , \\sigma )$ is the CDF of the Normal variable, it can be written as:\n",
    "\\begin{equation}\n",
    "F_X(x;\\mu , \\sigma )=\\Phi \\left({{x-\\mu } \\over \\sigma }\\right)\\quad \\quad \\quad (5)  \n",
    "\\end{equation}\n",
    "where $\\mu $ and $\\sigma $ are the mean and the standard deviation respectively, and $\\Phi (x)$ is the CDF of the standard Normal distribution $F_{N(0,1)}(x)$.\n",
    "\n",
    "Then, according to (1) and (3), the equation (5) is:\n",
    "\\begin{equation}\n",
    "\\xi =g(x)=x\\quad;\\quad\\eta =h(y)=\\Phi ^{-1}(y)\\quad;\\quad a={1 \\over \\sigma\n",
    "}\\quad;\\quad b=-\\frac{\\mu}{\\sigma}\\quad \\quad \\quad (6) \n",
    "\\end{equation}\n",
    "and the family of straight lines becomes\n",
    "\\begin{equation}\n",
    "\\eta =a\\xi +b={{\\xi -\\mu } \\over \\sigma } \\quad \\quad \\quad (7) \n",
    "\\end{equation}\n",
    "\n",
    "If the points $\\left( g(x_{i:n}), h\\!\\left(\\frac{i-0.5}{n}\\right) \\right) = \\left(x_{i:n}, \\Phi^{-1}\\!\\left(\\frac{i-0.5}{n}\\right) \\right)$ line up forming a straight line, the hypotesis of normality is accepted and the estimation of the parameteres $\\mu $ and $\\sigma $ is possible by fitting a line to themselves. Note that if $\\eta =0$ and $\\eta =1$ in (7) the result is:\n",
    "\\begin{equation} \\begin{array}{l}\\eta =0\\quad\\Rightarrow \\quad 0={{\\xi -\\mu }\n",
    "\\over \\sigma }\\quad\\Rightarrow \\quad\\xi_{\\eta =0} =\\mu \\\\\n",
    "  \\eta =1\\quad \\Rightarrow \\quad 1={{\\xi -\\mu } \\over \\sigma }\\quad\\Rightarrow\\quad \\xi_{\\eta =1} =\\mu +\\sigma\n",
    "\\end{array} \\end{equation}\n",
    "\n",
    "Next Figure shows a normal probability paper, where the axis of the ordinates has been transformed by $\\eta =\\Phi ^{-1}(y)$ and the axis of abscissas has no transformation. In this paper the points of the empirical distribution function are plotted directly: $\\left( x_{i:n}, \\frac{i-0.5}{n}\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b09c23-15a0-4b85-91db-1abb128212fe",
   "metadata": {},
   "source": [
    "<div><img alt=\"papel_normal\" src=\"./figuras/papel_normal.png\" width=\"500\"/></div>\n",
    "\n",
    "*Normal probability paper representing data from a sample of size 50 taken from a standardized Normal distribution.* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ee9c45-1189-4f12-85bd-bfc07fb02a29",
   "metadata": {},
   "source": [
    "## Normal probability paper in R\n",
    "\n",
    "In R you can easily draw the necessary data transformations to represent a\n",
    "set of data on Normal probability paper. To do this, just use the function\n",
    "`qnorm` like $h(y)$ to transform the empirical probabilities. \n",
    "\n",
    "However, in the instructions of the file *papeles.R* it is defined a function\n",
    "`papel.normal` that facilitates the representation. To use it just run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4ce049-b18e-4fe2-b3e3-4372db11fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "load(\"data/normal.rda\")  # load the variable named data\n",
    "papel.normal(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f19febe-a95a-4ded-abe2-f1db07f05557",
   "metadata": {},
   "source": [
    "The line that best fits the data using least squares can be obtained using the argument `show.fit`  which, as we can see, also indicates in the graph the value of $\\xi_{\\eta=0}=\\mu=-0.04$ and $\\xi_{\\eta=1}=\\mu+\\sigma= 1.01$, from which we can obtain the value of the parameters $\\mu=-0.045$ and $\\sigma=1.054$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be55fae-058c-4f51-ab58-2a91a918e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "papel.normal(data, show.fit=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb5e6f1-f444-4de0-9151-eaca290956fd",
   "metadata": {},
   "source": [
    "Note that the output of that function returns the previous values of $\\mu$ and $sigma$. These two values can be save in a variable to be used later for any other calculation. For instance to compute a probability as in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641543b1-1e2f-47a1-9eba-df8f29fdeeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "papelnorm_out <- papel.normal(data, show.fit=TRUE)\n",
    "# P(X<=2) \n",
    "pnorm(2, papelnorm_out$mean, papelnorm_out$sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0757ef45-457b-42e5-8489-03c45aaac7e3",
   "metadata": {},
   "source": [
    "Often the most extreme data in a sample do not fit a line well. This is because the regions with low probability of occurrence (the tails of the distribution) need very large sample sizes to have a sufficient number of data to adequately be represented. It is common to miss values in ranges that had a small probability of occurring and to appear values in other more unlikely ranges. For this reason, it is sometimes preferable to discard the most extreme data in the sample and fit the line only to the values that actually line up. The `papel.normal` function takes the argument `trim=N`, to remove `N` points from each tail before making the linear fit. \n",
    "\n",
    "Try this with the previous data and observe the effect on the line and the parameters of the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d6abe3-4561-4031-ae2f-6355dd5b85af",
   "metadata": {},
   "outputs": [],
   "source": [
    "papel.normal(data, show.fit=TRUE, trim=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4b9f3d-a332-4235-9a89-49637dd0961a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>PRACTICE ON YOUR OWN</strong>\n",
    "\n",
    "- The file *resistencias.rda* contains compressive strength data (in Kg/cm$^2$) of 40 concrete specimens.\n",
    "  1. Check if the hypothesis that the resistances are normally distributed can be accepted.\n",
    "  2. Get the mean strength and standard deviation from the fitted normal model.\n",
    "  3. If the characteristic resistance is defined as that which is exceeded by 95\\% of the samples and we consider the previous adjustment to be good, what is the characteristic resistance of this concrete?\n",
    "\n",
    "</n>\n",
    "\n",
    "- The file *datos_papeles.rda* contains 4 samples of 30 data each. When loading the file, they are available in the variables: data1, data2, data3 and data4. Plot the samples on normal probability paper and, if this model is acceptable, obtain the distribution parameters.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b02e7ca-4ffd-46d6-8386-814cacccb28f",
   "metadata": {},
   "source": [
    "# Exponencial probability paper\n",
    "\n",
    "The exponential probability paper transforms the exponential distribution function into a straight line. We are going to generalize the exponential random variable with respect to the one we have seen in theory, adding a location parameter $x_0$, that is:\n",
    "\n",
    "$F_{Ex(\\alpha,x_0)}(x) = 1- e^{-\\alpha(x-x_0)} \\qquad \\forall x \\ge x_0$\n",
    "\n",
    "This distribution is known as the shifted exponential distribution. Making $x_0=0$ returns the ordinary exponential distribution. If we make the transformations:\n",
    "\n",
    "$\\eta = h(y) = -\\ln(1-y) \\qquad \\xi=g(x) = x$\n",
    "\n",
    "we can write the shifted exponential as:\n",
    "\n",
    "$y = 1- e^{-\\alpha(x-x_0)}\n",
    "\\;\\Rightarrow\\; \\eta = h(y) = -\\ln(1-y) = \\alpha(x-x_0) = \\alpha(\\xi -x_0)$\n",
    "\n",
    "namely\n",
    "\n",
    "$\\eta = a\\xi +b$\n",
    "\n",
    "with $a=\\alpha$ and $b=-\\alpha x_0$.\n",
    "\n",
    "Again, the cuts with the lines $\\eta=0$ and $\\eta=1$, allow us to obtain the parameters:\n",
    "\\begin{eqnarray}\n",
    "\\eta = 0 & \\;\\Rightarrow\\; & 0 = \\alpha(\\xi -x_0) \\;\\Rightarrow\\; \\xi_{\\eta=0} = x_0 \\\\\n",
    "\\eta = 1 & \\;\\Rightarrow\\; & 1 = \\alpha(\\xi -x_0) \\;\\Rightarrow\\; \\xi_{\\eta=1} = x_0+\\alpha^{-1}\n",
    "\\end{eqnarray}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e171a1e-0f68-4c73-83a9-fb157729f966",
   "metadata": {},
   "source": [
    "## Exponential probability paper in R\n",
    "\n",
    "The file *papeles.R* includes the function `papel.exponential` to\n",
    "easily draw the necessary data transformations to represent a set of data on\n",
    "the exponential probability paper. To do this, just run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbddbe6b-09b9-470d-8959-9284f22e5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data <- rexp(40, 0.5)  # get 40 ramdom data from an Ex(0.5)\n",
    "papel.exponencial(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831bddf6-150b-4914-9407-bc86204285f1",
   "metadata": {},
   "source": [
    "As in the case of the function for the normal probability paper, this function takes the arguments `show.fit` and `trim`. It also has the argument `allow.shift=FALSE`, which sets the unshifted version of the exponential distribution (ie, forces $x_0=0$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8d7522-a9e5-4793-a0d1-8c12c7adb281",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>PRACTICE ON YOUR OWN</strong>\n",
    "\n",
    "Check if any of the samples in the file *datos_papeles.rda* responds to an exponential distribution and, in such a case, obtain its parameters.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08092c19-46b2-4e7c-8253-e174fd4647ff",
   "metadata": {},
   "source": [
    "# Maximal probability paper\n",
    "\n",
    "In this section we will deal with the use of the probability paper for the\n",
    "extreme case. Therefore, we will focus on analyzing the tails of the\n",
    "distribution (right or left according to interest) since this is the only\n",
    "part of the distribution function that governs the behavior of extremes,\n",
    "either maxima or minima.\n",
    "\n",
    "As an example we will consider the Normal and Exponential distributions to\n",
    "illustrate the role of queues in the extreme behavior. To this end, we are\n",
    "going to use some of the functions contained in the file *papeles.R* to\n",
    "represent samples of these two common distributions in maximal and minimal\n",
    "Gumbel probability paper. Then we will analyze in each case the domain of\n",
    "attraction of the extremes. \n",
    "\n",
    "We will use the file *distribuciones.rda* which contains data from a distribution $N(\\mu=6, \\sigma=2)$ and $Exp(\\alpha=0.2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10736481-ad63-4c91-851a-b76c567be7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data \n",
    "load(\"data/distribuciones.rda\")\n",
    "attach(distribuciones)\n",
    "# Maxima Gumbel probability paper\n",
    "papel.maximal(normal, x.transform=\"gumbel\", type=\"l\", lwd=2)\n",
    "title(\"Maxima Gumbel probability paper\")\n",
    "papel.maximal.lines(exp, col=\"red\", lwd=2)\n",
    "legend(\"topleft\", legend=c(\"Normal\", \"Exp\"),\n",
    "       col=c(\"black\",\"red\"), lty=1, box.lty=0, bg=\"white\")\n",
    "# Minima Gumbel probability paper\n",
    "papel.minimal(normal, x.transform=\"gumbel\", type=\"l\", lwd=2)\n",
    "title(\"Minima Gumbel probability paper\")\n",
    "papel.minimal.lines(exp, col=\"red\", lwd=2)\n",
    "legend(\"bottomright\", legend=c(\"Normal\", \"Exp\"),\n",
    "       col=c(\"black\",\"red\"), lty=1, box.lty=0, bg=\"white\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59173c71-4b49-494d-805f-9d521550f48c",
   "metadata": {},
   "source": [
    "In this case we have used the functions `papel.maximal.lines`\n",
    "and `papel.minimal.lines` from the file `papeles.R` which allow us to\n",
    "add the representation of another sample to the graph of the maximal or\n",
    "mininal probability paper plot already created. Furthermore, we have used\n",
    "the argument `type=\"l\"` that you already know since most of the plotting\n",
    "functions admit it, in order to join the data with a line instead of\n",
    "plotting the values with points, as in the previous graphs.\n",
    "\n",
    "The representation of these two distributions in the maximal Gumbel probability\n",
    "paper, shows a linearity of the right tail in both distributions, which confirms that both distributions belong to the Gumbel domain of attraction for maxima. \n",
    "\n",
    "The same distributions are represented in the minimal Gumbel probability paper. It is\n",
    "observed the linearity of the left tail of the Normal distribution, indicating\n",
    "thus that it belongs to the Gumbel domain of attraction for minima. In the case\n",
    "of the exponential distribution, a vertical slope is observed when approaching\n",
    "to the lower limits. This suggests a Weibull domain of attraction for minima.\n",
    "The analysis of both distributions confirms the attraction domains of the\n",
    "extremes that we had already obtained in class for these two distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5fb98e-aac0-4fbe-ad22-22411fda9d08",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>PRACTICE ON YOUR OWN</strong>\n",
    "\n",
    "- The file *T1007_phone_calls.txt* contains the times in seconds between $36$ consecutive calls made in an automatic telephone exchange (Castillo and Pruneda, 2001).\n",
    "  1. Load this data into R.\n",
    "  2. Plot these data on a exponential probability paper. Can we say that the occurrence of calls to this switchboard follows a homogeneous Poisson process?\n",
    "  3. Obtain the rate of occurrence of calls in the switchboard.\n",
    "  4. Estimate the domain of attraction for minima and maxima.\n",
    "  \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
